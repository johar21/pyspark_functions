{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c44cb0f-dbe8-4c03-8dc9-196762deb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad0158b-3f5b-4757-9b3d-697199628577",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=[('1','Raj'),('1','Yash'),('2','Harsh'),('3','Raj'),('4','Gopi')]\n",
    "schema=['No','Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3dd812-32ff-4169-b698-03105671361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/05 19:31:18 WARN Utils: Your hostname, Amandeeps-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.112 instead (on interface en0)\n",
      "24/06/05 19:31:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/05 19:31:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName('functions').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651a2250-f079-4fbc-b0ac-48c486441487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark_version- 3.5.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Spark_version- {spark.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56e0c6c8-372c-49c9-ba13-1482f1239f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.createDataFrame(data=data_df,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32639cff-c190-4572-93bc-372eca86e258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|No |Name |\n",
      "+---+-----+\n",
      "|1  |Raj  |\n",
      "|1  |Yash |\n",
      "|2  |Harsh|\n",
      "|3  |Raj  |\n",
      "|4  |Gopi |\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5871c43c-58a7-45b2-9b1c-ca6924e906d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_set,collect_list,array_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a90cccf-b136-436a-9017-e96f1a62da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_df=df.groupby('No').agg(collect_set('Name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b68df98-c616-476a-abb9-1d454da076b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:======================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+\n",
      "| No|collect_set(Name)|\n",
      "+---+-----------------+\n",
      "|  1|      [Raj, Yash]|\n",
      "|  2|          [Harsh]|\n",
      "|  3|            [Raj]|\n",
      "|  4|           [Gopi]|\n",
      "+---+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "aggregate_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c2aac-f42a-4ec4-8f3d-919256426a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
